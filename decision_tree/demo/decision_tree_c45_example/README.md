# C4.5å†³ç­–æ ‘ (Decision Tree C4.5) ä½¿ç”¨æŒ‡å—

## ğŸ“– ç®€ä»‹

C4.5å†³ç­–æ ‘æ˜¯ID3ç®—æ³•çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œä½¿ç”¨ä¿¡æ¯å¢ç›Šæ¯”ä½œä¸ºåˆ†è£‚å‡†åˆ™ï¼Œæ”¯æŒè¿ç»­ç‰¹å¾å¤„ç†ï¼Œå¹¶åŒ…å«å‰ªæåŠŸèƒ½æ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### è¿è¡Œç¤ºä¾‹
```bash
python main.py
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹

è¿è¡Œç¨‹åºåï¼Œæ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡å’ŒæŠ¥å‘Šå°†ä¿å­˜åœ¨ï¼š
```
./output/
```

### ç”Ÿæˆçš„æ–‡ä»¶åŒ…æ‹¬ï¼š

#### ğŸ“Š å¯è§†åŒ–å›¾ç‰‡ (15å¼ )
- `01_simple_dataset.png` - ç®€å•æ•°æ®é›†æ•£ç‚¹å›¾
- `01_simple_dataset_boundary.png` - ç®€å•æ•°æ®é›†å†³ç­–è¾¹ç•Œ
- `02_sklearn_train.png` - sklearnæ•°æ®é›†è®­ç»ƒç»“æœ
- `02_sklearn_test.png` - sklearnæ•°æ®é›†æµ‹è¯•ç»“æœ  
- `02_sklearn_boundary.png` - sklearnæ•°æ®é›†å†³ç­–è¾¹ç•Œ
- `03_iris_train.png` - é¸¢å°¾èŠ±æ•°æ®é›†è®­ç»ƒç»“æœ
- `03_iris_test.png` - é¸¢å°¾èŠ±æ•°æ®é›†æµ‹è¯•ç»“æœ
- `03_iris_boundary.png` - é¸¢å°¾èŠ±æ•°æ®é›†å†³ç­–è¾¹ç•Œ
- `04_wine_train.png` - è‘¡è„é…’æ•°æ®é›†è®­ç»ƒç»“æœ
- `04_wine_test.png` - è‘¡è„é…’æ•°æ®é›†æµ‹è¯•ç»“æœ
- `04_wine_boundary.png` - è‘¡è„é…’æ•°æ®é›†å†³ç­–è¾¹ç•Œ
- `05_unpruned.png` - å‰ªæå‰ç»“æœ
- `05_pruned.png` - å‰ªæåç»“æœ
- `05_unpruned_boundary.png` - å‰ªæå‰å†³ç­–è¾¹ç•Œ
- `05_pruned_boundary.png` - å‰ªæåå†³ç­–è¾¹ç•Œ

#### ğŸ“„ æŠ¥å‘Šæ–‡ä»¶
- `summary_report.txt` - è¯¦ç»†çš„å®éªŒæŠ¥å‘Šå’Œç®—æ³•è¯´æ˜

## ğŸ“Š æ•°æ®é›†è¦æ±‚

1. **ç‰¹å¾çŸ©é˜µ X**: å½¢çŠ¶ä¸º `(n_samples, n_features)` çš„æ•°ç»„
2. **æ ‡ç­¾å‘é‡ y**: æ”¯æŒå¤šåˆ†ç±»
3. **ç‰¹å¾ç±»å‹**: æ”¯æŒè¿ç»­å’Œç¦»æ•£ç‰¹å¾çš„æ··åˆ
4. **è‡ªåŠ¨å¤„ç†**: ç®—æ³•è‡ªåŠ¨è¯†åˆ«ç‰¹å¾ç±»å‹
5. **é—®é¢˜ç±»å‹**: é€‚ç”¨äºå¤šåˆ†ç±»é—®é¢˜

## ğŸ”§ åŸºæœ¬ç”¨æ³•

```python
from decision_tree_c45 import C45
import numpy as np

# åˆ›å»ºæ•°æ®
X = np.array([[1.2, 2.3], [2.1, 3.4], [3.5, 1.8], [4.2, 2.9]])
y = np.array([0, 1, 1, 0])

# è®­ç»ƒæ¨¡å‹
c45 = C45()
c45.fit(X, y)

# é¢„æµ‹
predictions = c45.predict(X)
print(predictions)

# å‰ªæ
c45.prune_pep()
pruned_predictions = c45.predict(X)
```

## ğŸ¯ æ¨èæ•°æ®é›†

### 1. Sklearnå†…ç½®æ•°æ®é›†
```python
from sklearn.datasets import make_classification, load_iris, load_wine

# ç”Ÿæˆåˆ†ç±»æ•°æ®
X, y = make_classification(n_samples=300, n_features=2, n_classes=3)

# é¸¢å°¾èŠ±æ•°æ®é›†
data = load_iris()
X, y = data.data, data.target

# è‘¡è„é…’æ•°æ®é›†
data = load_wine()
X, y = data.data, data.target
```

### 2. æ··åˆç‰¹å¾æ•°æ®
```python
import numpy as np

# è¿ç»­ç‰¹å¾ + ç¦»æ•£ç‰¹å¾
continuous_features = np.random.randn(100, 2)
discrete_features = np.random.choice(['A', 'B', 'C'], (100, 1))
X = np.column_stack([continuous_features, discrete_features])
```

## âš™ï¸ ç®—æ³•ç‰¹ç‚¹

- âœ… **ä¿¡æ¯å¢ç›Šæ¯”**: ä½¿ç”¨ä¿¡æ¯å¢ç›Šæ¯”é¿å…åå‘å¤šå€¼ç‰¹å¾
- âœ… **è¿ç»­ç‰¹å¾**: è‡ªåŠ¨å¤„ç†è¿ç»­å’Œç¦»æ•£ç‰¹å¾
- âœ… **å¤šå‰æ ‘**: ç”Ÿæˆå¤šåˆ†æ”¯å†³ç­–æ ‘
- âœ… **å‰ªæåŠŸèƒ½**: å†…ç½®PEPå‰ªæé˜²æ­¢è¿‡æ‹Ÿåˆ
- âœ… **å¤šåˆ†ç±»**: æ”¯æŒå¤šç±»åˆ«åˆ†ç±»é—®é¢˜
- âœ… **è‡ªåŠ¨é€‰æ‹©**: è‡ªåŠ¨é€‰æ‹©æœ€ä½³åˆ†è£‚ç‰¹å¾å’Œé˜ˆå€¼

## ğŸ” è¾“å‡ºè§£é‡Š

è¿è¡Œç¤ºä¾‹åï¼Œæ§åˆ¶å°ä¼šæ˜¾ç¤ºï¼š
- **å‡†ç¡®ç‡**: æ¨¡å‹åœ¨æ•°æ®ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡
- **æ ‘çš„èŠ‚ç‚¹æ•°**: å†³ç­–æ ‘çš„æ€»èŠ‚ç‚¹æ•°
- **æ ‘çš„æ·±åº¦**: å†³ç­–æ ‘çš„æœ€å¤§æ·±åº¦
- **å‰ªææ•ˆæœ**: å‰ªæå‰åçš„æ€§èƒ½å¯¹æ¯”

## ğŸ“ˆ æ€§èƒ½åˆ†æ

ä»ç¤ºä¾‹ç»“æœå¯ä»¥çœ‹å‡ºï¼š
1. **ç®€å•æ•°æ®é›†**: å‡†ç¡®ç‡é€šå¸¸åœ¨80-95%ä¹‹é—´
2. **çœŸå®æ•°æ®é›†**: åœ¨é¸¢å°¾èŠ±ã€è‘¡è„é…’ç­‰æ•°æ®ä¸Šè¡¨ç°ä¼˜ç§€
3. **å‰ªææ•ˆæœ**: å‰ªæå¯ä»¥æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
4. **è¿ç»­ç‰¹å¾**: ç›¸æ¯”ID3èƒ½æ›´å¥½å¤„ç†æ•°å€¼å‹ç‰¹å¾

## ğŸ“ æ³¨æ„äº‹é¡¹

1. ç®—æ³•ä¼šè‡ªåŠ¨è¯†åˆ«è¿ç»­å’Œç¦»æ•£ç‰¹å¾
2. æ”¯æŒå­—ç¬¦ä¸²ç±»å‹çš„ç¦»æ•£ç‰¹å¾
3. æ•°å€¼å‹ç‰¹å¾ä¼šè‡ªåŠ¨å¯»æ‰¾æœ€ä½³åˆ†å‰²ç‚¹
4. å‰ªæåŠŸèƒ½å¯ä»¥æœ‰æ•ˆé˜²æ­¢è¿‡æ‹Ÿåˆ
5. æ‰€æœ‰è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨ `./output/` æ–‡ä»¶å¤¹ä¸­

## ğŸ”„ ä¸å…¶ä»–ç®—æ³•å¯¹æ¯”

| ç‰¹æ€§ | ID3 | C4.5 | CART |
|------|-----|------|------|
| åˆ†è£‚å‡†åˆ™ | ä¿¡æ¯å¢ç›Š | ä¿¡æ¯å¢ç›Šæ¯” | åŸºå°¼ç³»æ•°/æ–¹å·® |
| ç‰¹å¾ç±»å‹ | ä»…ç¦»æ•£ | è¿ç»­+ç¦»æ•£ | è¿ç»­+ç¦»æ•£ |
| æ ‘ç»“æ„ | å¤šå‰ | å¤šå‰ | äºŒå‰ |
| å‰ªæ | æ—  | PEPå‰ªæ | CCPå‰ªæ |
| åº”ç”¨ | ç¦»æ•£ç‰¹å¾ | é€šç”¨åˆ†ç±» | åˆ†ç±»+å›å½’ | 